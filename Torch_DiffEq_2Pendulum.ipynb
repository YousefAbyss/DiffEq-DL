{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c2d5b7-5101-40e0-9206-fc7a50f4e5d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc517691-67dd-4ac2-b85d-78778076e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'notebook', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8704be0c-d227-4910-b3eb-3286b144ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    \"Defines a connected network\"\n",
    "\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.ELU\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS - 1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab75947a-9bae-49cf-b34d-736a6642ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(15)\n",
    "model = FCN(1, 2, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0153c28-7263-4dcc-85a7-41f346e47ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_boundary = torch.tensor(0.).view(-1, 1).requires_grad_(True)\n",
    "t_physics = torch.linspace(0, 1, 30).view(-1, 1).requires_grad_(True)\n",
    "t_test = torch.linspace(0, 1, 300).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab893ce-1546-45db-8034-f2f5e40ce9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_iter = 15001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf00615-1f50-4474-8a0a-7ac1789dc7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0665, -0.1339]], grad_fn=<AddmmBackward0>) \n",
      " tensor([[-0.0612]], grad_fn=<TBackward0>) \n",
      " tensor([[-0.0250]], grad_fn=<TBackward0>)\n"
     ]
    }
   ],
   "source": [
    "theta = model(t_boundary)\n",
    "theta_p = torch.autograd.grad(theta, t_boundary, torch.ones_like(theta), create_graph=True)[0]\n",
    "theta_p2 = torch.autograd.grad(theta_p, t_boundary, torch.ones_like(theta_p), create_graph=True)[0]\n",
    "print(theta, '\\n', theta_p, '\\n', theta_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f3d835-d2ba-4b8c-b6ee-1980c84a41da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (825590133.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    loss3 =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    theta = model(t_boundary)\n",
    "    loss1 = (torch.squeeze(theta) - 60) ** 2\n",
    "    lambda1 = 1\n",
    "\n",
    "    theta_p = torch.autograd.grad(theta, t_boundary, torch.ones_like(theta), create_graph=True)[0]\n",
    "    loss2 = (torch.squeeze(theta_p) - 0) ** 2\n",
    "    lamda2 = 1e-4\n",
    "    \n",
    "    theta = model(t_physics)\n",
    "    theta_p = torch.autograd.grad(theta, t_physics, torch.ones_like(theta), create_graph=True)[0]\n",
    "    theta_pp = torch.autograd.grad(theta_p, t_physics, torch.ones_like(theta_p), create_graph=True)[0]\n",
    "    loss3 = \n",
    "    lamda3 = 1e-4\n",
    "    \n",
    "    loss = loss1 + 1e-4 * loss2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 2500 == 0:\n",
    "        g = model(t_test).detach()\n",
    "        diff = str(np.round(np.max(np.abs(g - g_exact).numpy()), 5))\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.scatter(t_physics.detach()[:, 0],\n",
    "                    torch.zeros_like(t_physics)[:, 0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
    "        plt.scatter(t_boundary.detach()[:, 0],\n",
    "                    torch.zeros_like(t_boundary)[:, 0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
    "        plt.plot(t_test[:, 0], g_exact[:, 0], label=\"Exact\", color=\"tab:red\", alpha=0.6)\n",
    "        plt.plot(t_test[:, 0], g[:, 0], label=\"PINN\", color=\"tab:green\")\n",
    "        plt.title(f\"Training step {i}\")\n",
    "        plt.text(0.25, 9, f'max absolute difference: {diff}', size=10, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a1c99-6eb9-47c2-a074-b1ba0a9a5527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Physics",
   "language": "python",
   "name": "physics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
